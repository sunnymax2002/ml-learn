{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Making through Natural Language Processing\n",
    "\n",
    "How do we humans make decisions? Let's take an example to understand. Suppose, you want to enjoy the weekend by going to some place with your family. We put this down into simple sentences to visualize how our brain makes decision.\n",
    "\n",
    "* **Objective**: Enjoy the day with family\n",
    "\n",
    "The important keywords in above objective sentence are *enjoy*, *day* and *family*. Therefore, the first step is to extract the keywords from the objective statement.\n",
    "\n",
    "We use the popular NLTK library to extract such information from the objective statement. Here's the flow as taught by NLTK\n",
    "\n",
    "![](http://www.nltk.org/images/ie-architecture.png)\n",
    "\n",
    "Since we're starting with a single, simple sentence, we can skip the first step of tokenizing into sentences. The script below shows how to tokenize the sentence and add Part of Speech tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "> Enter the objective statement: \n\n> User provided objective statement: \nWe want to return back to India since we're not enjoying living in scotland\n\n> Tagging Objective Statement into Parts-of-Speech:\n[('We', 'PRP'), ('want', 'VBP'), ('to', 'TO'), ('return', 'VB'), ('back', 'RB'), ('to', 'TO'), ('India', 'NNP'), ('since', 'IN'), ('we', 'PRP'), (\"'re\", 'VBP'), ('not', 'RB'), ('enjoying', 'VBG'), ('living', 'VBG'), ('in', 'IN'), ('scotland', 'NN')]\nPRP: pronoun, personal\n    hers herself him himself hisself it itself me myself one oneself ours\n    ourselves ownself self she thee theirs them themselves they thou thy us\nWe PRP -> None\nVBP: verb, present tense, not 3rd person singular\n    predominate wrap resort sue twist spill cure lengthen brush terminate\n    appear tend stray glisten obtain comprise detest tease attract\n    emphasize mold postpone sever return wag ...\nwant VBP -> None\nTO: \"to\" as preposition or infinitive marker\n    to\nto TO -> None\nVB: verb, base form\n    ask assemble assess assign assume atone attention avoid bake balkanize\n    bank begin behold believe bend benefit bevel beware bless boil bomb\n    boost brace break bring broil brush build ...\nreturn VB -> None\nRB: adverb\n    occasionally unabatingly maddeningly adventurously professedly\n    stirringly prominently technologically magisterially predominately\n    swiftly fiscally pitilessly ...\nback RB -> None\nTO: \"to\" as preposition or infinitive marker\n    to\nto TO -> None\nNNP: noun, proper, singular\n    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n    Shannon A.K.C. Meltex Liverpool ...\nIndia NNP -> None\nIN: preposition or conjunction, subordinating\n    astride among uppon whether out inside pro despite on by throughout\n    below within for towards near behind atop around if like until below\n    next into if beside ...\nsince IN -> None\nPRP: pronoun, personal\n    hers herself him himself hisself it itself me myself one oneself ours\n    ourselves ownself self she thee theirs them themselves they thou thy us\nwe PRP -> None\nVBP: verb, present tense, not 3rd person singular\n    predominate wrap resort sue twist spill cure lengthen brush terminate\n    appear tend stray glisten obtain comprise detest tease attract\n    emphasize mold postpone sever return wag ...\n're VBP -> None\nRB: adverb\n    occasionally unabatingly maddeningly adventurously professedly\n    stirringly prominently technologically magisterially predominately\n    swiftly fiscally pitilessly ...\nnot RB -> None\nVBG: verb, present participle or gerund\n    telegraphing stirring focusing angering judging stalling lactating\n    hankerin' alleging veering capping approaching traveling besieging\n    encrypting interrupting erasing wincing ...\nenjoying VBG -> None\nVBG: verb, present participle or gerund\n    telegraphing stirring focusing angering judging stalling lactating\n    hankerin' alleging veering capping approaching traveling besieging\n    encrypting interrupting erasing wincing ...\nliving VBG -> None\nIN: preposition or conjunction, subordinating\n    astride among uppon whether out inside pro despite on by throughout\n    below within for towards near behind atop around if like until below\n    next into if beside ...\nin IN -> None\nNN: noun, common, singular or mass\n    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n    investment slide humour falloff slick wind hyena override subhumanity\n    machinist ...\nscotland NN -> None\n"
    }
   ],
   "source": [
    "import matplotlib as plt\n",
    "from typing import List\n",
    "import nltk\n",
    "\n",
    "# References\n",
    "#   NLTK book: http://www.nltk.org/book/\n",
    "#   NLTK sentiment analysis: https://www.digitalocean.com/community/tutorials/how-to-perform-sentiment-analysis-in-python-3-using-the-natural-language-toolkit-nltk\n",
    "\n",
    "# https://www.lexalytics.com/lexablog/context-analysis-nlphttps://www.lexalytics.com/lexablog/context-analysis-nlp\n",
    "\n",
    "\n",
    "def TagPartsOfSpeech(obj_statement: str) -> List[str]:\n",
    "    print(\"\\n> Tagging Objective Statement into Parts-of-Speech:\")\n",
    "\n",
    "    # Break text/sentence into tokens\n",
    "    tokens = nltk.word_tokenize(obj_statement)\n",
    "    # print(tokens)\n",
    "\n",
    "    # Add Part Of Speech tags to tokens\n",
    "    tagged = nltk.pos_tag(tokens) # Use default to allow subsequent classification possible: , tagset='universal')\n",
    "    print(tagged)\n",
    "\n",
    "    # KEEP-HELP: Meaning of each tag, and traversal through all tags\n",
    "    pos_tag_help = True\n",
    "    if(pos_tag_help == True):\n",
    "        for w, t in tagged:\n",
    "            print(w, t, '->', nltk.help.upenn_tagset(t))\n",
    "\n",
    "    return tagged\n",
    "\n",
    "# Step 0: Input objective statement from user\n",
    "print(\"> Enter the objective statement: \")\n",
    "obj_statement = \"We want to return back to India since we're not enjoying living in scotland\" # \"I want to enjoy the day with family\" # TODO str(input())\n",
    "\n",
    "print(\"\\n> User provided objective statement: \")\n",
    "print(obj_statement)\n",
    "\n",
    "# Step 1: Tag Objective statement into parts-of-speech\n",
    "tagged = TagPartsOfSpeech(obj_statement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to detect entities, which are simply groups of words describing an element of the sentence. For example, in the code below, we extract 'Noun Phrase (NP)', which is determiner-adjective(s)-noun chunk.\n",
    "\n",
    "Depending on what information one wants to extract, a RegExp can be defined to extract chunks from PoS tagged sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(S\n  (NP We/PRP)\n  (VP want/VBP to/TO return/VB back/RB to/TO)\n  (NP India/NNP)\n  since/IN\n  (NP we/PRP)\n  (VP 're/VBP not/RB enjoying/VBG living/VBG in/IN)\n  (NP scotland/NN))\n"
    }
   ],
   "source": [
    "# Finds chunks as specified by 'grammer' in PoS tagged sentence 'word_tagged_sent'\n",
    "def FindRegExpChunks(word_tagged_sent, grammer):\n",
    "    cp = nltk.RegexpParser(grammer, loop=4)\n",
    "\n",
    "    np_chunk = cp.parse(word_tagged_sent)\n",
    "    print(np_chunk)\n",
    "\n",
    "    return np_chunk\n",
    "\n",
    "# Reference: http://www.nltk.org/book/ch07.htmlhttp://www.nltk.org/book/ch07.html\n",
    "\n",
    "# Chunking example 1\n",
    "# grammar_np = r\"\"\"\n",
    "#     NP:\n",
    "#         {<DT>?<JJ>*<NN>}    # an optional determiner (DT) followed by any number of adjectives (JJ) and then a noun (NN)\n",
    "#         {<NN>+}             # one or more nouns together\n",
    "#     \"\"\"\n",
    "\n",
    "grammar = r\"\"\"\n",
    "  NP:   {<DT|JJ|PRP|NN.*>+}                         # Chunk sequences of DT, JJ, NN\n",
    "  VP:   {<VB.*|RB|TO>+<IN>*}                             # Chunk for verb-adverb-verb...\n",
    "  \"\"\"\n",
    "\n",
    "#    P_P:   {<IN><NP>}                    # Chunk prepositions followed by NP\n",
    "#  V_P: {<VB.*><NP|PP|CLAUSE>+$}      # Chunk verbs and their arguments\n",
    "\n",
    "  # CLAUSE: {<NP><VP>}                # Chunk NP, VP\n",
    "\n",
    "chunk_np = FindRegExpChunks(tagged, grammar)\n",
    "\n",
    "# Chinking example (exlude part of sentence)\n",
    "# grammer2 = r\"\"\"\n",
    "#   NP:\n",
    "#     {<DT><NN>}  # Chunk DT followed by NN\n",
    "#     }<NN|IN>+{       # Chink sequences of NN and IN\n",
    "#     {<.*>+}          # Chunk everything\n",
    "#   \"\"\"\n",
    "# chunk2 = FindRegExpChunks(tagged, grammer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "    # TODO Find synonyms etc.\n",
    "    # for w, t in tagged:\n",
    "    #     for syn in wordnet.synsets(w):\n",
    "    #         print(w, t, syn)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38232bitc8226c58ec484784b2102751f26fc1ba",
   "display_name": "Python 3.8.2 32-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}